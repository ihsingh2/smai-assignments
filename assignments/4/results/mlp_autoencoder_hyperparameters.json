{
    "activation": "relu",
    "lr": 0.0001,
    "num_hidden_layers": 4
}
