{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Literal, Tuple\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "\n",
    "PROJECT_DIR = '../..'\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "from models.cnn import CNN, MultiLabelCNN\n",
    "from models.knn import KNN\n",
    "from models.MLP import get_activation, get_loss\n",
    "from performance_measures import ClassificationMeasures, MultiLabelClassificationMeasures, \\\n",
    "                                                                                RegressionMeasures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_data(dataset_path: str, split: Literal['train', 'val', 'test'], \\\n",
    "                    count_digits: bool = False) -> List[Tuple[npt.NDArray[np.uint8], str | int]]:\n",
    "    \"\"\" Loads the images and labels for a split of the Multi MNIST (double_mnist) dataset. \"\"\"\n",
    "\n",
    "    # Image, label pairs\n",
    "    X, y = [], []\n",
    "\n",
    "    for descriptor in os.listdir(f'{dataset_path}/{split}'):\n",
    "\n",
    "        # Label\n",
    "        if count_digits:\n",
    "            label = len(descriptor) if descriptor != '0' else 0\n",
    "        else:\n",
    "            label = descriptor\n",
    "\n",
    "        # Image\n",
    "        for image_path in os.listdir(f'{dataset_path}/{split}/{descriptor}'):\n",
    "            image = cv2.imread(f'{dataset_path}/{split}/{descriptor}/{image_path}', 0)\n",
    "\n",
    "            # Store image and label\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encoding(labels: List[str]):\n",
    "    \"\"\" Creates one hot encoded vectors for each label value. \"\"\"\n",
    "\n",
    "    out = []\n",
    "    for label in labels:\n",
    "        encoding = np.zeros(10)\n",
    "        if label != '0':\n",
    "            encoding[[int(c) for c in label]] = 1\n",
    "        out.append(encoding)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiMNISTDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, dataset_path: str, split: Literal['train', 'val', 'test'], \\\n",
    "                                                                task: Literal['count', 'predict']):\n",
    "\n",
    "        if task == 'count':\n",
    "            self.images, self.labels = load_mnist_data(dataset_path, split, count_digits=True)\n",
    "        else:\n",
    "            self.images, self.labels = load_mnist_data(dataset_path, split, count_digits=False)\n",
    "            self.labels = one_hot_encoding(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.images[idx]), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'train', 'count')\n",
    "val_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'val', 'count')\n",
    "test_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'test', 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify the key hyperparameters to tune, including learning rate, dropout rate, the number of convolutional layers and optimizer choice.\n",
    "# 2. Plot training and validation loss graphs for at least 5 different combinations of hyperparameters for each of the classification and regression models.\n",
    "# 3. Identify the best perfoming model and include relevant plots and analyses in the report. Report accuracies of both classification and regression CNN on validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature maps reveal which patterns and features the CNN is focusing on at various layers. To obtain feature maps, you can access the outputs after each block of [ convolution, activation function, and pooling layer ] during the forward pass of the model. Visualize feature maps of any three images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'train', 'predict')\n",
    "val_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'val', 'predict')\n",
    "test_set = MultiMNISTDataset(f'{PROJECT_DIR}/data/external/double_mnist', 'test', 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Experiment with different values of hyperparameters such as learning rate, number of epochs, dropout rate, the number of convolutional layers and optimizer choice.\n",
    "# 2. Plot training and validation loss graphs for 5 or more such combinations of hyperparameters.\n",
    "# 3. Identify the best perfoming model and include relevant plots and analyses in the report. For this model, report both the exact match accuracy and hamming accuracy on train, val and test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iiit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
